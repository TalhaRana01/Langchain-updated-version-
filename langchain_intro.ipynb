{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc693a5",
   "metadata": {},
   "source": [
    "# Langchain Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# # print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "# # print(os.getenv(\"GOOGLE_API_KEY\"))\n",
    "# # print(os.getenv(\"GROQ_API_KEY\"))\n",
    "# # print(os.getenv(\"CLAUDE_API_KEY\"))\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# models = init_chat_model(\"gpt-4o\")\n",
    "\n",
    "# # print(models)\n",
    "\n",
    "\n",
    "# # invoke a model \n",
    "# response = models.invoke(\"Hello!, How are you?\")\n",
    "\n",
    "# # print(response.content)\n",
    "# response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a0750",
   "metadata": {},
   "source": [
    "## Google Gemini Model Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf90cc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Pakistan is **Islamabad**.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "models = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "\n",
    "response = models.invoke(\"what is the capital of Pakistan?\")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbf338d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ChatOpenaiAI\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "response = model.invoke(\"Hello, How are you?\")\n",
    "\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945f1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Genai Chat\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# # model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "# model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# response = model.invoke(\"Hello, How are you?\")\n",
    "\n",
    "# response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46740d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GROQ MODEL Integration \n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "# # model = init_chat_model(\"groq:qwen/qwen3-32b\")\n",
    "# model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "\n",
    "# response = model.invoke(\"Why do parrots talk?\")\n",
    "\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20613f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "# response = model.invoke(\"How are you bro?\")\n",
    "\n",
    "# response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96850b98",
   "metadata": {},
   "source": [
    "# Streaming And Batch \n",
    "\n",
    "Most models can stream their output content while it is being generated. By displaying output progressively, streaming significantly improves user experience, particularly for longer responses. Calling stream() returns an iterator that yields output chunks as they produced. You can use a loop to process each chunk in real-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613fb78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are designed to think and act like humans. This technology encompasses a range of capabilities, including learning, reasoning, problem-solving, perception, and language understanding. At its core, AI aims to create systems that can perform tasks typically requiring human intelligence, such as recognizing patterns, making decisions, and understanding natural language. The development of AI has been propelled by advancements in machine learning, where algorithms learn from data to improve their performance over time. AI applications are ubiquitous, spanning diverse fields such as healthcare, finance, transportation, and entertainment. For instance, in healthcare, AI algorithms assist in diagnosing diseases and personalizing treatment plans, while in finance, they help in fraud detection and algorithmic trading. However, the rise of AI also raises ethical and societal concerns, including job displacement and issues surrounding data privacy. Balancing innovation with responsible deployment is crucial as we navigate the evolving landscape of artificial intelligence. As research continues to advance, the potential of AI to transform industries and improve quality of life remains immense, inviting both excitement and caution as we explore its full capabilities.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 226, 'prompt_tokens': 17, 'total_tokens': 243, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cs4zGT1gONn0JKuiHBdkw670QyzKK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b69b3-53a4-7a72-9308-db3c85192059-0', usage_metadata={'input_tokens': 17, 'output_tokens': 226, 'total_tokens': 243, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Write me a 200 words paragraph on Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6414ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Artificial| Intelligence| (|AI|)| stands| as| one| of| the| most| transformative| technologies| of| the| |21|st| century|,| impacting| diverse| sectors| such| as| healthcare|,| finance|,| education|,| and| transportation|.| At| its| core|,| AI| encompasses| machine| learning|,| natural| language| processing|,| and| robotics|,| enabling| systems| to| perform| tasks| that| typically| require| human| intelligence|.| By| analyzing| vast| amounts| of| data|,| AI| algorithms| can| identify| patterns|,| make| predictions|,| and| automate| routine| processes|,| leading| to| enhanced| efficiency| and| accuracy|.| In| healthcare|,| for| instance|,| AI|-powered| diagnostic| tools| assist| doctors| in| detecting| diseases| earlier| by| analyzing| medical| images| or| patient| data|.| In| finance|,| AI| algorithms| optimize| trading| strategies| and| mitigate| risks| by| assessing| market| trends| rapidly|.| Moreover|,| the| advancements| in| natural| language| processing| have| led| to| more| intuitive| human|-com|puter| interactions|,| as| seen| in| virtual| assistants| like| Siri| and| Alexa|.| However|,| the| rapid| growth| of| AI| also| raises| ethical| concerns|,| particularly| regarding| privacy|,| employment| displacement|,| and| decision|-making| transparency|.| As| societies| navigate| these| challenges|,| the| potential| for| responsible| and| equitable| AI| development| remains| a| central| focus| for| researchers|,| policymakers|,| and| industry| leaders|.| Ultimately|,| the| future| of| AI| promises| not| only| innovation| but| also| a| vital| opportunity| to| reshape| how| we| live| and| work|,| emphasizing| the| need| for| thoughtful| guidance| in| its| continued| evolution|.||||"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(\"Write me a 200 words paragraph on Artificial Intelligence\"):\n",
    "  print(chunk.text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381514a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Updated_Langchain_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
